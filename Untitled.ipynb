{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fb4a457",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\vpved/.cache\\torch\\hub\\NVIDIA_DeepLearningExamples_torchhub\n",
      "C:\\Users\\vpved/.cache\\torch\\hub\\NVIDIA_DeepLearningExamples_torchhub\\PyTorch\\Classification\\ConvNets\\image_classification\\models\\common.py:13: UserWarning: pytorch_quantization module not found, quantization will not be available\n",
      "  warnings.warn(\n",
      "C:\\Users\\vpved/.cache\\torch\\hub\\NVIDIA_DeepLearningExamples_torchhub\\PyTorch\\Classification\\ConvNets\\image_classification\\models\\efficientnet.py:17: UserWarning: pytorch_quantization module not found, quantization will not be available\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Download pre-trained Tacotron 2 weights\n",
    "tacotron2_model = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_tacotron2', model_math='fp16')\n",
    "tacotron2_model.eval()\n",
    "\n",
    "# Save the pre-trained weights\n",
    "torch.save(tacotron2_model.state_dict(), 'pretrained_tacotron2.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76d140a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-26 11:19:53,380 - INFO - Hyperparameters and directories set up\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Your provided directory structure and hyperparameters\n",
    "BASE_DIR = \"./\"\n",
    "DATA_DIR = os.path.join(BASE_DIR, 'emov-DB')\n",
    "PROCESSED_DATA_DIR = os.path.join(BASE_DIR, 'processed_data')\n",
    "MODEL_DIR = os.path.join(BASE_DIR, 'saved_models')\n",
    "\n",
    "EMOTIONS = ['Neutral', 'Sleepy', 'Angry', 'Disgusted', 'Amused']\n",
    "EMOTION_FILE_COUNTS = {\n",
    "    'Neutral': 373,\n",
    "    'Sleepy': 520,\n",
    "    'Angry': 317,\n",
    "    'Disgusted': 347,\n",
    "    'Amused': 309\n",
    "}\n",
    "\n",
    "HPARAMS = {\n",
    "    'training_files': os.path.join(BASE_DIR, 'metadata.csv'),\n",
    "    'val_files': os.path.join(BASE_DIR, 'metadata.csv'),  # Use a separate validation set in practice\n",
    "    'epochs': 10,\n",
    "    'batch_size': 32,\n",
    "    'learning_rate': 1e-4,\n",
    "    'sampling_rate': 22050,\n",
    "    'filter_length': 1024,\n",
    "    'hop_length': 256,\n",
    "    'win_length': 1024,\n",
    "    'n_mel_channels': 80,\n",
    "    'mel_fmin': 0.0,\n",
    "    'mel_fmax': 8000.0,\n",
    "    'EMOTIONS': EMOTIONS\n",
    "}\n",
    "\n",
    "logger.info(\"Hyperparameters and directories set up\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df6d2e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-26 11:36:59,068 - INFO - Script started\n",
      "2024-06-26 11:36:59,075 - INFO - Hyperparameters: {'training_files': './metadata.csv', 'val_files': './metadata.csv', 'epochs': 10, 'batch_size': 32, 'learning_rate': 0.0001, 'sampling_rate': 22050, 'filter_length': 1024, 'hop_length': 256, 'win_length': 1024, 'n_mel_channels': 80, 'mel_fmin': 0.0, 'mel_fmax': 8000.0, 'EMOTIONS': ['Neutral', 'Sleepy', 'Angry', 'Disgusted', 'Amused']}\n",
      "2024-06-26 11:36:59,079 - INFO - Directories: BASE_DIR=./, DATA_DIR=./emov-DB, PROCESSED_DATA_DIR=./processed_data, MODEL_DIR=./saved_models\n",
      "2024-06-26 11:36:59,084 - INFO - EmotionalSpeechDataset class defined\n",
      "2024-06-26 11:36:59,088 - INFO - EmotionalTacotron2 class defined\n",
      "2024-06-26 11:36:59,088 - INFO - Loading pre-trained Tacotron2 model\n",
      "Using cache found in C:\\Users\\vpved/.cache\\torch\\hub\\NVIDIA_DeepLearningExamples_torchhub\n",
      "C:\\Users\\vpved/.cache\\torch\\hub\\NVIDIA_DeepLearningExamples_torchhub\\PyTorch\\Classification\\ConvNets\\image_classification\\models\\common.py:13: UserWarning: pytorch_quantization module not found, quantization will not be available\n",
      "  warnings.warn(\n",
      "C:\\Users\\vpved/.cache\\torch\\hub\\NVIDIA_DeepLearningExamples_torchhub\\PyTorch\\Classification\\ConvNets\\image_classification\\models\\efficientnet.py:17: UserWarning: pytorch_quantization module not found, quantization will not be available\n",
      "  warnings.warn(\n",
      "2024-06-26 11:37:01,620 - DEBUG - bytecode dump:\n",
      ">          0\tNOP(arg=None, lineno=1039)\n",
      "           2\tRESUME(arg=0, lineno=1039)\n",
      "           4\tLOAD_FAST(arg=0, lineno=1042)\n",
      "           6\tLOAD_CONST(arg=1, lineno=1042)\n",
      "           8\tBINARY_SUBSCR(arg=None, lineno=1042)\n",
      "          12\tLOAD_FAST(arg=0, lineno=1042)\n",
      "          14\tLOAD_CONST(arg=2, lineno=1042)\n",
      "          16\tBINARY_SUBSCR(arg=None, lineno=1042)\n",
      "          20\tCOMPARE_OP(arg=68, lineno=1042)\n",
      "          24\tLOAD_FAST(arg=0, lineno=1042)\n",
      "          26\tLOAD_CONST(arg=1, lineno=1042)\n",
      "          28\tBINARY_SUBSCR(arg=None, lineno=1042)\n",
      "          32\tLOAD_FAST(arg=0, lineno=1042)\n",
      "          34\tLOAD_CONST(arg=3, lineno=1042)\n",
      "          36\tBINARY_SUBSCR(arg=None, lineno=1042)\n",
      "          40\tCOMPARE_OP(arg=92, lineno=1042)\n",
      "          44\tBINARY_OP(arg=1, lineno=1042)\n",
      "          48\tRETURN_VALUE(arg=None, lineno=1042)\n",
      "2024-06-26 11:37:01,620 - DEBUG - pending: deque([State(pc_initial=0 nstack_initial=0)])\n",
      "2024-06-26 11:37:01,626 - DEBUG - stack: []\n",
      "2024-06-26 11:37:01,630 - DEBUG - state.pc_initial: State(pc_initial=0 nstack_initial=0)\n",
      "2024-06-26 11:37:01,631 - DEBUG - dispatch pc=0, inst=NOP(arg=None, lineno=1039)\n",
      "2024-06-26 11:37:01,631 - DEBUG - stack []\n",
      "2024-06-26 11:37:01,635 - DEBUG - dispatch pc=2, inst=RESUME(arg=0, lineno=1039)\n",
      "2024-06-26 11:37:01,635 - DEBUG - stack []\n",
      "2024-06-26 11:37:01,640 - DEBUG - dispatch pc=4, inst=LOAD_FAST(arg=0, lineno=1042)\n",
      "2024-06-26 11:37:01,641 - DEBUG - stack []\n",
      "2024-06-26 11:37:01,644 - DEBUG - dispatch pc=6, inst=LOAD_CONST(arg=1, lineno=1042)\n",
      "2024-06-26 11:37:01,644 - DEBUG - stack ['$x4.0']\n",
      "2024-06-26 11:37:01,653 - DEBUG - dispatch pc=8, inst=BINARY_SUBSCR(arg=None, lineno=1042)\n",
      "2024-06-26 11:37:01,655 - DEBUG - stack ['$x4.0', '$const6.1']\n",
      "2024-06-26 11:37:01,655 - DEBUG - dispatch pc=12, inst=LOAD_FAST(arg=0, lineno=1042)\n",
      "2024-06-26 11:37:01,655 - DEBUG - stack ['$8binary_subscr.2']\n",
      "2024-06-26 11:37:01,660 - DEBUG - dispatch pc=14, inst=LOAD_CONST(arg=2, lineno=1042)\n",
      "2024-06-26 11:37:01,660 - DEBUG - stack ['$8binary_subscr.2', '$x12.3']\n",
      "2024-06-26 11:37:01,663 - DEBUG - dispatch pc=16, inst=BINARY_SUBSCR(arg=None, lineno=1042)\n",
      "2024-06-26 11:37:01,665 - DEBUG - stack ['$8binary_subscr.2', '$x12.3', '$const14.4']\n",
      "2024-06-26 11:37:01,668 - DEBUG - dispatch pc=20, inst=COMPARE_OP(arg=68, lineno=1042)\n",
      "2024-06-26 11:37:01,668 - DEBUG - stack ['$8binary_subscr.2', '$16binary_subscr.5']\n",
      "2024-06-26 11:37:01,668 - DEBUG - dispatch pc=24, inst=LOAD_FAST(arg=0, lineno=1042)\n",
      "2024-06-26 11:37:01,673 - DEBUG - stack ['$20compare_op.6']\n",
      "2024-06-26 11:37:01,674 - DEBUG - dispatch pc=26, inst=LOAD_CONST(arg=1, lineno=1042)\n",
      "2024-06-26 11:37:01,674 - DEBUG - stack ['$20compare_op.6', '$x24.7']\n",
      "2024-06-26 11:37:01,676 - DEBUG - dispatch pc=28, inst=BINARY_SUBSCR(arg=None, lineno=1042)\n",
      "2024-06-26 11:37:01,676 - DEBUG - stack ['$20compare_op.6', '$x24.7', '$const26.8']\n",
      "2024-06-26 11:37:01,676 - DEBUG - dispatch pc=32, inst=LOAD_FAST(arg=0, lineno=1042)\n",
      "2024-06-26 11:37:01,676 - DEBUG - stack ['$20compare_op.6', '$28binary_subscr.9']\n",
      "2024-06-26 11:37:01,684 - DEBUG - dispatch pc=34, inst=LOAD_CONST(arg=3, lineno=1042)\n",
      "2024-06-26 11:37:01,688 - DEBUG - stack ['$20compare_op.6', '$28binary_subscr.9', '$x32.10']\n",
      "2024-06-26 11:37:01,688 - DEBUG - dispatch pc=36, inst=BINARY_SUBSCR(arg=None, lineno=1042)\n",
      "2024-06-26 11:37:01,688 - DEBUG - stack ['$20compare_op.6', '$28binary_subscr.9', '$x32.10', '$const34.11']\n",
      "2024-06-26 11:37:01,695 - DEBUG - dispatch pc=40, inst=COMPARE_OP(arg=92, lineno=1042)\n",
      "2024-06-26 11:37:01,695 - DEBUG - stack ['$20compare_op.6', '$28binary_subscr.9', '$36binary_subscr.12']\n",
      "2024-06-26 11:37:01,695 - DEBUG - dispatch pc=44, inst=BINARY_OP(arg=1, lineno=1042)\n",
      "2024-06-26 11:37:01,700 - DEBUG - stack ['$20compare_op.6', '$40compare_op.13']\n",
      "2024-06-26 11:37:01,701 - DEBUG - dispatch pc=48, inst=RETURN_VALUE(arg=None, lineno=1042)\n",
      "2024-06-26 11:37:01,702 - DEBUG - stack ['$binop_and_44.14']\n",
      "2024-06-26 11:37:01,702 - DEBUG - end state. edges=[]\n",
      "2024-06-26 11:37:01,702 - DEBUG - -------------------------Prune PHIs-------------------------\n",
      "2024-06-26 11:37:01,702 - DEBUG - Used_phis: defaultdict(<class 'set'>, {State(pc_initial=0 nstack_initial=0): set()})\n",
      "2024-06-26 11:37:01,702 - DEBUG - defmap: {}\n",
      "2024-06-26 11:37:01,702 - DEBUG - phismap: defaultdict(<class 'set'>, {})\n",
      "2024-06-26 11:37:01,710 - DEBUG - changing phismap: defaultdict(<class 'set'>, {})\n",
      "2024-06-26 11:37:01,712 - DEBUG - keep phismap: {}\n",
      "2024-06-26 11:37:01,714 - DEBUG - new_out: defaultdict(<class 'dict'>, {})\n",
      "2024-06-26 11:37:01,714 - DEBUG - ----------------------DONE Prune PHIs-----------------------\n",
      "2024-06-26 11:37:01,719 - DEBUG - block_infos State(pc_initial=0 nstack_initial=0):\n",
      "AdaptBlockInfo(insts=((0, {}), (2, {}), (4, {'res': '$x4.0'}), (6, {'res': '$const6.1'}), (8, {'index': '$const6.1', 'target': '$x4.0', 'res': '$8binary_subscr.2'}), (12, {'res': '$x12.3'}), (14, {'res': '$const14.4'}), (16, {'index': '$const14.4', 'target': '$x12.3', 'res': '$16binary_subscr.5'}), (20, {'lhs': '$8binary_subscr.2', 'rhs': '$16binary_subscr.5', 'res': '$20compare_op.6'}), (24, {'res': '$x24.7'}), (26, {'res': '$const26.8'}), (28, {'index': '$const26.8', 'target': '$x24.7', 'res': '$28binary_subscr.9'}), (32, {'res': '$x32.10'}), (34, {'res': '$const34.11'}), (36, {'index': '$const34.11', 'target': '$x32.10', 'res': '$36binary_subscr.12'}), (40, {'lhs': '$28binary_subscr.9', 'rhs': '$36binary_subscr.12', 'res': '$40compare_op.13'}), (44, {'op': '&', 'lhs': '$20compare_op.6', 'rhs': '$40compare_op.13', 'res': '$binop_and_44.14'}), (48, {'retval': '$binop_and_44.14', 'castval': '$48return_value.15'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})\n",
      "2024-06-26 11:37:01,719 - DEBUG - label 0:\n",
      "    x = arg(0, name=x)                       ['x']\n",
      "    $const6.1 = const(int, 0)                ['$const6.1']\n",
      "    $8binary_subscr.2 = getitem(value=x, index=$const6.1, fn=<built-in function getitem>) ['$8binary_subscr.2', '$const6.1', 'x']\n",
      "    $const14.4 = const(int, -1)              ['$const14.4']\n",
      "    $16binary_subscr.5 = getitem(value=x, index=$const14.4, fn=<built-in function getitem>) ['$16binary_subscr.5', '$const14.4', 'x']\n",
      "    $20compare_op.6 = $8binary_subscr.2 > $16binary_subscr.5 ['$16binary_subscr.5', '$20compare_op.6', '$8binary_subscr.2']\n",
      "    $const26.8 = const(int, 0)               ['$const26.8']\n",
      "    $28binary_subscr.9 = getitem(value=x, index=$const26.8, fn=<built-in function getitem>) ['$28binary_subscr.9', '$const26.8', 'x']\n",
      "    $const34.11 = const(int, 1)              ['$const34.11']\n",
      "    $36binary_subscr.12 = getitem(value=x, index=$const34.11, fn=<built-in function getitem>) ['$36binary_subscr.12', '$const34.11', 'x']\n",
      "    $40compare_op.13 = $28binary_subscr.9 >= $36binary_subscr.12 ['$28binary_subscr.9', '$36binary_subscr.12', '$40compare_op.13']\n",
      "    $binop_and_44.14 = $20compare_op.6 & $40compare_op.13 ['$20compare_op.6', '$40compare_op.13', '$binop_and_44.14']\n",
      "    $48return_value.15 = cast(value=$binop_and_44.14) ['$48return_value.15', '$binop_and_44.14']\n",
      "    return $48return_value.15                ['$48return_value.15']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-26 11:37:01,725 - DEBUG - bytecode dump:\n",
      ">          0\tNOP(arg=None, lineno=1045)\n",
      "           2\tRESUME(arg=0, lineno=1045)\n",
      "           4\tLOAD_FAST(arg=0, lineno=1048)\n",
      "           6\tLOAD_CONST(arg=1, lineno=1048)\n",
      "           8\tBINARY_SUBSCR(arg=None, lineno=1048)\n",
      "          12\tLOAD_FAST(arg=0, lineno=1048)\n",
      "          14\tLOAD_CONST(arg=2, lineno=1048)\n",
      "          16\tBINARY_SUBSCR(arg=None, lineno=1048)\n",
      "          20\tCOMPARE_OP(arg=2, lineno=1048)\n",
      "          24\tLOAD_FAST(arg=0, lineno=1048)\n",
      "          26\tLOAD_CONST(arg=1, lineno=1048)\n",
      "          28\tBINARY_SUBSCR(arg=None, lineno=1048)\n",
      "          32\tLOAD_FAST(arg=0, lineno=1048)\n",
      "          34\tLOAD_CONST(arg=3, lineno=1048)\n",
      "          36\tBINARY_SUBSCR(arg=None, lineno=1048)\n",
      "          40\tCOMPARE_OP(arg=26, lineno=1048)\n",
      "          44\tBINARY_OP(arg=1, lineno=1048)\n",
      "          48\tRETURN_VALUE(arg=None, lineno=1048)\n",
      "2024-06-26 11:37:01,727 - DEBUG - pending: deque([State(pc_initial=0 nstack_initial=0)])\n",
      "2024-06-26 11:37:01,727 - DEBUG - stack: []\n",
      "2024-06-26 11:37:01,727 - DEBUG - state.pc_initial: State(pc_initial=0 nstack_initial=0)\n",
      "2024-06-26 11:37:01,727 - DEBUG - dispatch pc=0, inst=NOP(arg=None, lineno=1045)\n",
      "2024-06-26 11:37:01,727 - DEBUG - stack []\n",
      "2024-06-26 11:37:01,727 - DEBUG - dispatch pc=2, inst=RESUME(arg=0, lineno=1045)\n",
      "2024-06-26 11:37:01,735 - DEBUG - stack []\n",
      "2024-06-26 11:37:01,735 - DEBUG - dispatch pc=4, inst=LOAD_FAST(arg=0, lineno=1048)\n",
      "2024-06-26 11:37:01,737 - DEBUG - stack []\n",
      "2024-06-26 11:37:01,737 - DEBUG - dispatch pc=6, inst=LOAD_CONST(arg=1, lineno=1048)\n",
      "2024-06-26 11:37:01,737 - DEBUG - stack ['$x4.0']\n",
      "2024-06-26 11:37:01,737 - DEBUG - dispatch pc=8, inst=BINARY_SUBSCR(arg=None, lineno=1048)\n",
      "2024-06-26 11:37:01,737 - DEBUG - stack ['$x4.0', '$const6.1']\n",
      "2024-06-26 11:37:01,743 - DEBUG - dispatch pc=12, inst=LOAD_FAST(arg=0, lineno=1048)\n",
      "2024-06-26 11:37:01,743 - DEBUG - stack ['$8binary_subscr.2']\n",
      "2024-06-26 11:37:01,743 - DEBUG - dispatch pc=14, inst=LOAD_CONST(arg=2, lineno=1048)\n",
      "2024-06-26 11:37:01,743 - DEBUG - stack ['$8binary_subscr.2', '$x12.3']\n",
      "2024-06-26 11:37:01,749 - DEBUG - dispatch pc=16, inst=BINARY_SUBSCR(arg=None, lineno=1048)\n",
      "2024-06-26 11:37:01,749 - DEBUG - stack ['$8binary_subscr.2', '$x12.3', '$const14.4']\n",
      "2024-06-26 11:37:01,749 - DEBUG - dispatch pc=20, inst=COMPARE_OP(arg=2, lineno=1048)\n",
      "2024-06-26 11:37:01,751 - DEBUG - stack ['$8binary_subscr.2', '$16binary_subscr.5']\n",
      "2024-06-26 11:37:01,751 - DEBUG - dispatch pc=24, inst=LOAD_FAST(arg=0, lineno=1048)\n",
      "2024-06-26 11:37:01,751 - DEBUG - stack ['$20compare_op.6']\n",
      "2024-06-26 11:37:01,751 - DEBUG - dispatch pc=26, inst=LOAD_CONST(arg=1, lineno=1048)\n",
      "2024-06-26 11:37:01,751 - DEBUG - stack ['$20compare_op.6', '$x24.7']\n",
      "2024-06-26 11:37:01,751 - DEBUG - dispatch pc=28, inst=BINARY_SUBSCR(arg=None, lineno=1048)\n",
      "2024-06-26 11:37:01,759 - DEBUG - stack ['$20compare_op.6', '$x24.7', '$const26.8']\n",
      "2024-06-26 11:37:01,760 - DEBUG - dispatch pc=32, inst=LOAD_FAST(arg=0, lineno=1048)\n",
      "2024-06-26 11:37:01,761 - DEBUG - stack ['$20compare_op.6', '$28binary_subscr.9']\n",
      "2024-06-26 11:37:01,761 - DEBUG - dispatch pc=34, inst=LOAD_CONST(arg=3, lineno=1048)\n",
      "2024-06-26 11:37:01,761 - DEBUG - stack ['$20compare_op.6', '$28binary_subscr.9', '$x32.10']\n",
      "2024-06-26 11:37:01,761 - DEBUG - dispatch pc=36, inst=BINARY_SUBSCR(arg=None, lineno=1048)\n",
      "2024-06-26 11:37:01,761 - DEBUG - stack ['$20compare_op.6', '$28binary_subscr.9', '$x32.10', '$const34.11']\n",
      "2024-06-26 11:37:01,761 - DEBUG - dispatch pc=40, inst=COMPARE_OP(arg=26, lineno=1048)\n",
      "2024-06-26 11:37:01,769 - DEBUG - stack ['$20compare_op.6', '$28binary_subscr.9', '$36binary_subscr.12']\n",
      "2024-06-26 11:37:01,769 - DEBUG - dispatch pc=44, inst=BINARY_OP(arg=1, lineno=1048)\n",
      "2024-06-26 11:37:01,769 - DEBUG - stack ['$20compare_op.6', '$40compare_op.13']\n",
      "2024-06-26 11:37:01,772 - DEBUG - dispatch pc=48, inst=RETURN_VALUE(arg=None, lineno=1048)\n",
      "2024-06-26 11:37:01,772 - DEBUG - stack ['$binop_and_44.14']\n",
      "2024-06-26 11:37:01,774 - DEBUG - end state. edges=[]\n",
      "2024-06-26 11:37:01,775 - DEBUG - -------------------------Prune PHIs-------------------------\n",
      "2024-06-26 11:37:01,776 - DEBUG - Used_phis: defaultdict(<class 'set'>, {State(pc_initial=0 nstack_initial=0): set()})\n",
      "2024-06-26 11:37:01,777 - DEBUG - defmap: {}\n",
      "2024-06-26 11:37:01,777 - DEBUG - phismap: defaultdict(<class 'set'>, {})\n",
      "2024-06-26 11:37:01,779 - DEBUG - changing phismap: defaultdict(<class 'set'>, {})\n",
      "2024-06-26 11:37:01,785 - DEBUG - keep phismap: {}\n",
      "2024-06-26 11:37:01,787 - DEBUG - new_out: defaultdict(<class 'dict'>, {})\n",
      "2024-06-26 11:37:01,787 - DEBUG - ----------------------DONE Prune PHIs-----------------------\n",
      "2024-06-26 11:37:01,789 - DEBUG - block_infos State(pc_initial=0 nstack_initial=0):\n",
      "AdaptBlockInfo(insts=((0, {}), (2, {}), (4, {'res': '$x4.0'}), (6, {'res': '$const6.1'}), (8, {'index': '$const6.1', 'target': '$x4.0', 'res': '$8binary_subscr.2'}), (12, {'res': '$x12.3'}), (14, {'res': '$const14.4'}), (16, {'index': '$const14.4', 'target': '$x12.3', 'res': '$16binary_subscr.5'}), (20, {'lhs': '$8binary_subscr.2', 'rhs': '$16binary_subscr.5', 'res': '$20compare_op.6'}), (24, {'res': '$x24.7'}), (26, {'res': '$const26.8'}), (28, {'index': '$const26.8', 'target': '$x24.7', 'res': '$28binary_subscr.9'}), (32, {'res': '$x32.10'}), (34, {'res': '$const34.11'}), (36, {'index': '$const34.11', 'target': '$x32.10', 'res': '$36binary_subscr.12'}), (40, {'lhs': '$28binary_subscr.9', 'rhs': '$36binary_subscr.12', 'res': '$40compare_op.13'}), (44, {'op': '&', 'lhs': '$20compare_op.6', 'rhs': '$40compare_op.13', 'res': '$binop_and_44.14'}), (48, {'retval': '$binop_and_44.14', 'castval': '$48return_value.15'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})\n",
      "2024-06-26 11:37:01,794 - DEBUG - label 0:\n",
      "    x = arg(0, name=x)                       ['x']\n",
      "    $const6.1 = const(int, 0)                ['$const6.1']\n",
      "    $8binary_subscr.2 = getitem(value=x, index=$const6.1, fn=<built-in function getitem>) ['$8binary_subscr.2', '$const6.1', 'x']\n",
      "    $const14.4 = const(int, -1)              ['$const14.4']\n",
      "    $16binary_subscr.5 = getitem(value=x, index=$const14.4, fn=<built-in function getitem>) ['$16binary_subscr.5', '$const14.4', 'x']\n",
      "    $20compare_op.6 = $8binary_subscr.2 < $16binary_subscr.5 ['$16binary_subscr.5', '$20compare_op.6', '$8binary_subscr.2']\n",
      "    $const26.8 = const(int, 0)               ['$const26.8']\n",
      "    $28binary_subscr.9 = getitem(value=x, index=$const26.8, fn=<built-in function getitem>) ['$28binary_subscr.9', '$const26.8', 'x']\n",
      "    $const34.11 = const(int, 1)              ['$const34.11']\n",
      "    $36binary_subscr.12 = getitem(value=x, index=$const34.11, fn=<built-in function getitem>) ['$36binary_subscr.12', '$const34.11', 'x']\n",
      "    $40compare_op.13 = $28binary_subscr.9 <= $36binary_subscr.12 ['$28binary_subscr.9', '$36binary_subscr.12', '$40compare_op.13']\n",
      "    $binop_and_44.14 = $20compare_op.6 & $40compare_op.13 ['$20compare_op.6', '$40compare_op.13', '$binop_and_44.14']\n",
      "    $48return_value.15 = cast(value=$binop_and_44.14) ['$48return_value.15', '$binop_and_44.14']\n",
      "    return $48return_value.15                ['$48return_value.15']\n",
      "\n",
      "2024-06-26 11:37:06,520 - INFO - Pre-trained Tacotron2 model loaded\n",
      "2024-06-26 11:37:06,522 - INFO - Initializing EmotionalTacotron2 with num_emotions=5, emotion_embed_dim=64\n",
      "2024-06-26 11:37:06,530 - INFO - New embedding layer created with input dim=148 and output dim=576\n",
      "2024-06-26 11:37:06,534 - INFO - EmotionalTacotron2 model created\n",
      "2024-06-26 11:37:06,542 - INFO - Preparing dataset and dataloader\n",
      "2024-06-26 11:37:06,550 - INFO - Initializing EmotionalSpeechDataset with csv_file=./metadata.csv, root_dir=./emov-DB\n",
      "2024-06-26 11:37:06,576 - INFO - Dataset initialized with 1786 samples\n",
      "2024-06-26 11:37:06,590 - DEBUG - Emotion to ID mapping: {'Neutral': 0, 'Sleepy': 1, 'Angry': 2, 'Disgusted': 3, 'Amused': 4}\n",
      "2024-06-26 11:37:06,592 - INFO - Dataset and dataloader prepared with 1786 samples\n",
      "2024-06-26 11:37:10,998 - INFO - Loss function and optimizer set up\n",
      "2024-06-26 11:37:10,998 - INFO - Using device: cuda\n",
      "2024-06-26 11:37:11,166 - INFO - Starting epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "logger.info(\"Script started\")\n",
    "\n",
    "#  directory structure and hyperparameters\n",
    "BASE_DIR = \"./\"\n",
    "DATA_DIR = os.path.join(BASE_DIR, 'emov-DB')\n",
    "PROCESSED_DATA_DIR = os.path.join(BASE_DIR, 'processed_data')\n",
    "MODEL_DIR = os.path.join(BASE_DIR, 'saved_models')\n",
    "\n",
    "EMOTIONS = ['Neutral', 'Sleepy', 'Angry', 'Disgusted', 'Amused']\n",
    "EMOTION_FILE_COUNTS = {\n",
    "    'Neutral': 373,\n",
    "    'Sleepy': 520,\n",
    "    'Angry': 317,\n",
    "    'Disgusted': 347,\n",
    "    'Amused': 309\n",
    "}\n",
    "\n",
    "HPARAMS = {\n",
    "    'training_files': os.path.join(BASE_DIR, 'metadata.csv'),\n",
    "    'val_files': os.path.join(BASE_DIR, 'metadata.csv'),  # Use a separate validation set in practice\n",
    "    'epochs': 10,\n",
    "    'batch_size': 32,\n",
    "    'learning_rate': 1e-4,\n",
    "    'sampling_rate': 22050,\n",
    "    'filter_length': 1024,\n",
    "    'hop_length': 256,\n",
    "    'win_length': 1024,\n",
    "    'n_mel_channels': 80,\n",
    "    'mel_fmin': 0.0,\n",
    "    'mel_fmax': 8000.0,\n",
    "    'EMOTIONS': EMOTIONS\n",
    "}\n",
    "\n",
    "logger.info(f\"Hyperparameters: {HPARAMS}\")\n",
    "logger.info(f\"Directories: BASE_DIR={BASE_DIR}, DATA_DIR={DATA_DIR}, PROCESSED_DATA_DIR={PROCESSED_DATA_DIR}, MODEL_DIR={MODEL_DIR}\")\n",
    "\n",
    "# Custom dataset class\n",
    "class EmotionalSpeechDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir):\n",
    "        logger.info(f\"Initializing EmotionalSpeechDataset with csv_file={csv_file}, root_dir={root_dir}\")\n",
    "        self.metadata = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.emotion_to_id = {emotion: i for i, emotion in enumerate(EMOTIONS)}\n",
    "        logger.info(f\"Dataset initialized with {len(self.metadata)} samples\")\n",
    "        logger.debug(f\"Emotion to ID mapping: {self.emotion_to_id}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.metadata)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        logger.debug(f\"Getting item {idx}\")\n",
    "        audio_path = os.path.join(self.root_dir, self.metadata.iloc[idx, 0])\n",
    "        text = self.metadata.iloc[idx, 1]\n",
    "        emotion = self.metadata.iloc[idx, 2]\n",
    "\n",
    "        logger.debug(f\"Loading sample {idx}: audio_path={audio_path}, text={text}, emotion={emotion}\")\n",
    "\n",
    "        try:\n",
    "            # Load and preprocess audio\n",
    "            audio, _ = librosa.load(audio_path, sr=HPARAMS['sampling_rate'])\n",
    "            logger.debug(f\"Audio loaded: shape={audio.shape}, min={audio.min()}, max={audio.max()}\")\n",
    "            \n",
    "            mel = librosa.feature.melspectrogram(\n",
    "                y=audio,\n",
    "                sr=HPARAMS['sampling_rate'],\n",
    "                n_mels=HPARAMS['n_mel_channels'],\n",
    "                fmin=HPARAMS['mel_fmin'],\n",
    "                fmax=HPARAMS['mel_fmax']\n",
    "            )\n",
    "            mel = librosa.power_to_db(mel, ref=np.max)\n",
    "            logger.debug(f\"Mel spectrogram computed: shape={mel.shape}, min={mel.min()}, max={mel.max()}\")\n",
    "\n",
    "            return {\n",
    "                'text': torch.LongTensor(self.text_to_sequence(text)),\n",
    "                'mel': torch.FloatTensor(mel),\n",
    "                'emotion': torch.LongTensor([self.emotion_to_id[emotion]])\n",
    "            }\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing item {idx}: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def text_to_sequence(self, text):\n",
    "        # Implement text to sequence conversion here\n",
    "        # This is a placeholder implementation\n",
    "        sequence = [ord(c) for c in text.lower()]\n",
    "        logger.debug(f\"Text to sequence: '{text}' -> {sequence}\")\n",
    "        return sequence\n",
    "\n",
    "logger.info(\"EmotionalSpeechDataset class defined\")\n",
    "\n",
    "# Modified Tacotron2 model with emotion embedding\n",
    "class EmotionalTacotron2(nn.Module):\n",
    "    def __init__(self, tacotron2_model, num_emotions, emotion_embed_dim):\n",
    "        super(EmotionalTacotron2, self).__init__()\n",
    "        logger.info(f\"Initializing EmotionalTacotron2 with num_emotions={num_emotions}, emotion_embed_dim={emotion_embed_dim}\")\n",
    "        self.tacotron2 = tacotron2_model\n",
    "        self.emotion_embedding = nn.Embedding(num_emotions, emotion_embed_dim)\n",
    "        \n",
    "        # Modify the encoder to accept emotion embeddings\n",
    "        old_embed_dim = self.tacotron2.embedding.embedding_dim\n",
    "        self.new_embedding = nn.Embedding(\n",
    "            self.tacotron2.embedding.num_embeddings,\n",
    "            old_embed_dim + emotion_embed_dim\n",
    "        )\n",
    "        logger.info(f\"New embedding layer created with input dim={self.tacotron2.embedding.num_embeddings} and output dim={old_embed_dim + emotion_embed_dim}\")\n",
    "\n",
    "    def forward(self, text, emotion):\n",
    "        logger.debug(f\"EmotionalTacotron2 forward pass: text shape={text.shape}, emotion shape={emotion.shape}\")\n",
    "        emotion_embed = self.emotion_embedding(emotion)\n",
    "        text_embed = self.new_embedding(text)\n",
    "        \n",
    "        # Combine text and emotion embeddings\n",
    "        combined_embed = torch.cat((text_embed, emotion_embed.unsqueeze(1).expand(-1, text_embed.size(1), -1)), dim=-1)\n",
    "        logger.debug(f\"Combined embedding shape: {combined_embed.shape}\")\n",
    "        \n",
    "        # Pass through the encoder\n",
    "        encoder_outputs = self.tacotron2.encoder(combined_embed)\n",
    "        logger.debug(f\"Encoder output shape: {encoder_outputs.shape}\")\n",
    "        \n",
    "        # Pass through the decoder\n",
    "        mel_outputs, mel_outputs_postnet, gate_outputs, alignments = self.tacotron2.decoder(\n",
    "            encoder_outputs,\n",
    "            memory=None,\n",
    "            processed_memory=None,\n",
    "            attention_weights=None\n",
    "        )\n",
    "        logger.debug(f\"Decoder output shapes: mel={mel_outputs.shape}, mel_postnet={mel_outputs_postnet.shape}, gate={gate_outputs.shape}, alignments={alignments.shape}\")\n",
    "        \n",
    "        return mel_outputs, mel_outputs_postnet, gate_outputs, alignments\n",
    "\n",
    "logger.info(\"EmotionalTacotron2 class defined\")\n",
    "\n",
    "# Load the pre-trained Tacotron2 model\n",
    "logger.info(\"Loading pre-trained Tacotron2 model\")\n",
    "tacotron2_model = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_tacotron2', model_math='fp16')\n",
    "tacotron2_model.eval()\n",
    "logger.info(\"Pre-trained Tacotron2 model loaded\")\n",
    "\n",
    "# Create the emotional Tacotron2 model\n",
    "emotional_tacotron2 = EmotionalTacotron2(tacotron2_model, num_emotions=len(EMOTIONS), emotion_embed_dim=64)\n",
    "logger.info(\"EmotionalTacotron2 model created\")\n",
    "\n",
    "# Prepare dataset and dataloader\n",
    "logger.info(\"Preparing dataset and dataloader\")\n",
    "dataset = EmotionalSpeechDataset(HPARAMS['training_files'], DATA_DIR)\n",
    "dataloader = DataLoader(dataset, batch_size=HPARAMS['batch_size'], shuffle=True, num_workers=4)\n",
    "logger.info(f\"Dataset and dataloader prepared with {len(dataset)} samples\")\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(emotional_tacotron2.parameters(), lr=HPARAMS['learning_rate'])\n",
    "logger.info(\"Loss function and optimizer set up\")\n",
    "\n",
    "# Training loop\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "logger.info(f\"Using device: {device}\")\n",
    "emotional_tacotron2.to(device)\n",
    "\n",
    "try:\n",
    "    for epoch in range(HPARAMS['epochs']):\n",
    "        logger.info(f\"Starting epoch {epoch+1}/{HPARAMS['epochs']}\")\n",
    "        emotional_tacotron2.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        for batch_idx, batch in enumerate(dataloader):\n",
    "            logger.debug(f\"Processing batch {batch_idx+1}/{len(dataloader)}\")\n",
    "            \n",
    "            try:\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                logger.debug(\"Moving batch to device\")\n",
    "                text = batch['text'].to(device)\n",
    "                mel_target = batch['mel'].to(device)\n",
    "                emotion = batch['emotion'].to(device)\n",
    "                logger.debug(f\"Batch shapes: text={text.shape}, mel_target={mel_target.shape}, emotion={emotion.shape}\")\n",
    "\n",
    "                logger.debug(\"Running forward pass\")\n",
    "                mel_output, mel_output_postnet, _, _ = emotional_tacotron2(text, emotion)\n",
    "\n",
    "                logger.debug(\"Calculating loss\")\n",
    "                loss = criterion(mel_output, mel_target) + criterion(mel_output_postnet, mel_target)\n",
    "                logger.debug(f\"Loss: {loss.item()}\")\n",
    "                \n",
    "                logger.debug(\"Running backward pass\")\n",
    "                loss.backward()\n",
    "                \n",
    "                logger.debug(\"Optimizer step\")\n",
    "                optimizer.step()\n",
    "\n",
    "                total_loss += loss.item()\n",
    "\n",
    "                if batch_idx % 10 == 0:\n",
    "                    logger.info(f\"Epoch {epoch+1}, Batch {batch_idx+1}/{len(dataloader)}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error processing batch {batch_idx+1}: {str(e)}\")\n",
    "                raise\n",
    "\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        logger.info(f\"Epoch {epoch+1}/{HPARAMS['epochs']}, Average Loss: {avg_loss:.4f}\")\n",
    "\n",
    "        # Save checkpoint\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            checkpoint_path = os.path.join(MODEL_DIR, f'emotional_tacotron2_checkpoint_epoch_{epoch+1}.pth')\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': emotional_tacotron2.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': avg_loss,\n",
    "            }, checkpoint_path)\n",
    "            logger.info(f\"Checkpoint saved: {checkpoint_path}\")\n",
    "\n",
    "except Exception as e:\n",
    "    logger.error(f\"An error occurred during training: {str(e)}\")\n",
    "    raise\n",
    "\n",
    "# Save the final model\n",
    "final_model_path = os.path.join(MODEL_DIR, 'emotional_tacotron2_final.pth')\n",
    "torch.save(emotional_tacotron2.state_dict(), final_model_path)\n",
    "logger.info(f\"Final model saved: {final_model_path}\")\n",
    "\n",
    "logger.info(\"Training completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5097823e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
